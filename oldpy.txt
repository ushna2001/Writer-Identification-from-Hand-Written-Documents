from flask import render_template, Flask, request, jsonify
from transformers import ViTForImageClassification
import torch
from PIL import Image
import torchvision.transforms as transforms
import os
from werkzeug.utils import secure_filename
import numpy as np

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

app = Flask(__name__)

model_path = './static/models/v2/'  # Update with the path to your saved model
model = ViTForImageClassification.from_pretrained(model_path).to(device)

UPLOAD_FOLDER = './static/uploaded_images'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

last_uploaded_file_path = None

@app.route('/upload_image', methods=['POST'])
def upload_image():
    global last_uploaded_file_path

    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400
    if file:
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        # Store the path of the uploaded file
        last_uploaded_file_path = filepath
        print(f"File uploaded: {last_uploaded_file_path}")  # Debug print
        return jsonify({'message': 'File uploaded successfully', 'filepath': filepath}), 200

    return jsonify({'error': 'File upload failed'}), 500

@app.route('/identify_writer', methods=['POST'])
def identify_writer():
    global last_uploaded_file_path

    print(f"Last uploaded file path: {last_uploaded_file_path}")  # Debug print

    if last_uploaded_file_path:
        try:
            print(f"Image path: {last_uploaded_file_path}")  # Debug print
            prediction = predict(last_uploaded_file_path)
            print(f"Prediction: {prediction}")  # Debug print
            return jsonify({'prediction': prediction}), 200
        except Exception as e:
            print(f"Error during prediction: {e}")  # Debug print
            return jsonify({'error': f"Error during prediction: {e}"}), 500
    else:
        return jsonify({'error': 'No image uploaded yet. Please upload an image first.'}), 400

def predict(image_path):
    try:
        id2label = {0: 'Aakefa Qaiser',
 1: 'Aaminah Qaiser',
 2: 'Abdur Rehman',
 3: 'Anusha Hamza',
 4: 'Ariba Yasmeen',
 5: 'Asher Hussain Rizvi',
 6: 'Bazil Bashir Faridi',
 7: 'Ebad Ali',
 8: 'Farah Hussain',
 9: 'Farhana Qaiser',
 10: 'Haseeb Shabbir',
 11: 'Laiba Azam',
 12: 'Malaika Ali',
 13: 'Marium Rizvi',
 14: 'Muhammad Ali Rizvi',
 15: 'Rameez Khan',
 16: 'Shagufta Aleem',
 17: 'Shaheer Ali Agha',
 18: 'Ushna Hamza',
 19: 'Usman Rizvi'}
        image = Image.open(image_path)
        print("Image opened successfully")  # Debug print

        # Preprocess the image
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Update with your normalization values
        ])
        input_image = transform(image)
        print("Image transformed successfully")  # Debug print

        # Perform inference
        with torch.no_grad():
            inputs = input_image.unsqueeze(0).to(device)  # Add batch dimension
            outputs = model(inputs)
        
        predicted_class_idx = torch.argmax(outputs.logits).item()
        # predicted_label = str(predicted_class_idx)  # Adjust this based on your label mapping
        predicted_label = id2label[predicted_class_idx]
        return predicted_label
    except Exception as e:
        print(f"Error in predict function: {e}")  # Debug print
        raise e

@app.route('/home', methods=['GET', 'POST'])
def home():
    return render_template('index.html')

@app.route('/get_last_uploaded_file_path', methods=['GET'])
def get_last_uploaded_file_path():
    return f'Last uploaded file path: {last_uploaded_file_path}'

if __name__ == '__main__':
    app.run(debug=True)
